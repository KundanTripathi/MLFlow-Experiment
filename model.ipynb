{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "from lightgbm import LGBMClassifier as lgb\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, log_loss, precision_recall_curve, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data =  pd.read_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"Heart Attack Data Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    data.drop_duplicates(inplace = True)  #drop duplicates\n",
    "    data = pd.get_dummies(data, columns = ['cp', 'slope', 'thal', 'ca'], drop_first = True) #onehot encoding of categorical features\n",
    "    \n",
    "    X = data.drop('target',axis = 1)\n",
    "    y = data.target\n",
    "    \n",
    "    scale = SS().fit(X)\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42,stratify = y)\n",
    "    X_train = scale.transform(X_train)\n",
    "    X_test = scale.transform(X_test)\n",
    "    \n",
    "    return X_train, X_train, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train, y_train, y_test = data_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X_train, y_train, model):\n",
    "    LogR = LR().fit(X_train,y_train)\n",
    "    RF = rfc().fit(X_train,y_train)\n",
    "    DT = dtc().fit(X_train,y_train)\n",
    "    LGB = lgb().fit(X_train,y_train)\n",
    "    XGB = xgb().fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
